{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb31fe5865c74bffa1d1998b02ab3bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d9084cd415a4fe3813adc1a1e0a1cf8",
              "IPY_MODEL_0a99f9d606684d44a04e27067a64c856",
              "IPY_MODEL_387e2e74f7464d72a1786a0ac0c15860"
            ],
            "layout": "IPY_MODEL_4f1158a641064b9a9ba7590a2a18db62"
          }
        },
        "4d9084cd415a4fe3813adc1a1e0a1cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21eb4962cf734e989c869c4a4ae50522",
            "placeholder": "​",
            "style": "IPY_MODEL_387be76ad2574881a772b8912ab670f3",
            "value": " 47%"
          }
        },
        "0a99f9d606684d44a04e27067a64c856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efee8ff236eb48e1b1a41711b2fbd46f",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efef01e7d37d4702acc82fc6e11a6519",
            "value": 474
          }
        },
        "387e2e74f7464d72a1786a0ac0c15860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cee2fa67082490bbc548156b8662c18",
            "placeholder": "​",
            "style": "IPY_MODEL_41698135b00b43cdb653378a665c49d2",
            "value": " 474/1000 [16:05&lt;16:14,  1.85s/it]"
          }
        },
        "4f1158a641064b9a9ba7590a2a18db62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21eb4962cf734e989c869c4a4ae50522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387be76ad2574881a772b8912ab670f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efee8ff236eb48e1b1a41711b2fbd46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efef01e7d37d4702acc82fc6e11a6519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cee2fa67082490bbc548156b8662c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41698135b00b43cdb653378a665c49d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3[extra]\n",
        "!pip install gymnasium-robotics"
      ],
      "metadata": {
        "id": "ZAsYGnevLuBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3001587e-b891-47ac-e311-8c7f1d375671"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable_baselines3[extra] in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (2.8.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable_baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3[extra]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable_baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable_baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable_baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable_baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: gymnasium-robotics in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
            "Requirement already satisfied: mujoco>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (3.3.7)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (1.2.1)\n",
            "Requirement already satisfied: PettingZoo>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (1.25.0)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (3.1.6)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (2.37.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (75.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gymnasium-robotics) (25.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.2.0->gymnasium-robotics) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.2.0->gymnasium-robotics) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.2.0->gymnasium-robotics) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.0.3->gymnasium-robotics) (3.0.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.2.0->gymnasium-robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.2.0->gymnasium-robotics) (1.13.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.2.0->gymnasium-robotics) (2.10.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.2.0->gymnasium-robotics) (3.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio->gymnasium-robotics) (11.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco>=2.2.0->gymnasium-robotics) (3.23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import gymnasium_robotics\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from typing import Tuple, List, Dict"
      ],
      "metadata": {
        "id": "UDS0XP9hqKA0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mm-SWsBBd2KK"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self, max_len: int, n_envs: int, state_size: int, act_size: int, device: str):\n",
        "    self.device = device\n",
        "    self.max_len = max_len\n",
        "    self.n_envs = n_envs\n",
        "    self.state_size = state_size\n",
        "    self.act_size = act_size\n",
        "    self.buffer = []\n",
        "\n",
        "  def add_frame(self, state, next_state, action, reward, finished) -> None:\n",
        "    mask = 1 - finished\n",
        "    self.buffer.append((state, next_state, action, reward, mask))\n",
        "\n",
        "  def random_sample(self, batch_size: int) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
        "    states = torch.zeros(batch_size, self.n_envs, self.state_size, device=self.device)\n",
        "    next_states = torch.zeros(batch_size, self.n_envs, self.state_size, device=self.device)\n",
        "    actions = torch.zeros(batch_size, self.n_envs, self.act_size, device=self.device)\n",
        "    rewards = torch.zeros(batch_size, self.n_envs, device=self.device)\n",
        "    mask = torch.zeros(batch_size, self.n_envs, device=self.device)\n",
        "    sample_tuple = (states, next_states, actions, rewards, mask)\n",
        "\n",
        "    samples = np.random.randint(0, len(self.buffer), size=(batch_size,))\n",
        "\n",
        "    for i, s in enumerate(samples):\n",
        "      for t in range(len(sample_tuple)):\n",
        "        sample_tuple[t][i] = self.buffer[s][t]\n",
        "\n",
        "    states = sample_tuple[0].reshape(batch_size * self.n_envs, self.state_size)\n",
        "    next_states = sample_tuple[1].reshape(batch_size * self.n_envs, self.state_size)\n",
        "    actions = sample_tuple[2].reshape(batch_size * self.n_envs, self.act_size)\n",
        "    rewards = sample_tuple[3].reshape(batch_size * self.n_envs)\n",
        "    mask = sample_tuple[4].reshape(batch_size * self.n_envs)\n",
        "\n",
        "    return states, next_states, actions, rewards, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size: int, net_arch: List[int], activation: nn.Module):\n",
        "    super(MLP, self).__init__()\n",
        "    layers = [nn.Linear(input_size, net_arch[0]), activation()]\n",
        "    for i in range(len(net_arch) - 1):\n",
        "      layers.append(nn.Linear(net_arch[i], net_arch[i+1]))\n",
        "      layers.append(activation())\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tensor:\n",
        "    return self.model(x)\n",
        "\n",
        "class Actor(nn.Module):\n",
        "  def __init__(self, input_size: int, output_size: int, net_arch: List[int], activation: nn.Module):\n",
        "    super(Actor, self).__init__()\n",
        "    self.base = MLP(input_size, net_arch, activation)\n",
        "    self.mu_head = nn.Linear(net_arch[-1], output_size)\n",
        "    self.sigma_head = nn.Linear(net_arch[-1], output_size)\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "    x = self.base(x)\n",
        "    mu = self.mu_head(x)\n",
        "    log_sigma = self.sigma_head(x)\n",
        "    return mu, log_sigma\n",
        "\n",
        "  def eval_state(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "    mu, log_sigma = self.forward(x)\n",
        "    sigma = log_sigma.exp()\n",
        "    pi_s = torch.distributions.Normal(mu, sigma)\n",
        "    action = pi_s.rsample()\n",
        "    bounded_action = torch.tanh(action) # shift the result to valid region\n",
        "    log_prob = pi_s.log_prob(action).sum(axis=-1)\n",
        "    tanh_fix = 2 * (np.log(2) - action - nn.functional.softplus(-2*action))\n",
        "    log_prob -= tanh_fix.sum(axis=1)\n",
        "    return bounded_action, log_prob\n",
        "\n",
        "  def get_action(self, x: Tensor) -> Tensor:\n",
        "    mu, log_sigma = self.forward(x)\n",
        "    sigma = log_sigma.exp()\n",
        "    pi_s = torch.distributions.Normal(mu, sigma)\n",
        "    action = pi_s.sample()\n",
        "    return torch.tanh(action)\n",
        "\n",
        "\n",
        "class QNet(nn.Module):\n",
        "  def __init__(self, input_size: int, net_arch: List[int], activation: nn.Module):\n",
        "    super(QNet, self).__init__()\n",
        "    self.base = MLP(input_size, net_arch, activation)\n",
        "    self.value_head = nn.Linear(net_arch[-1], 1)\n",
        "\n",
        "  def forward(self, s: Tensor, a: Tensor) -> Tensor:\n",
        "    x = torch.cat((s, a), dim = 1)\n",
        "    x = self.base(x)\n",
        "    x = self.value_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2SzEfWwCs6yQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAC(nn.Module):\n",
        "  def __init__(self, obs_size: int, act_size: int, lr: float, gamma: float, tau: float, device: str):\n",
        "    super(SAC, self).__init__()\n",
        "    self.activation = nn.ReLU\n",
        "    self.actor = Actor(obs_size, act_size, [64, 64, 64, 64], self.activation)\n",
        "    self.Q1 = QNet(obs_size + act_size, [64, 64, 64], self.activation)\n",
        "    self.Q2 = QNet(obs_size + act_size, [64, 64, 64], self.activation)\n",
        "    self.critic1 = QNet(obs_size + act_size, [64, 64, 64], self.activation)\n",
        "    self.critic2 = QNet(obs_size + act_size, [64, 64, 64], self.activation)\n",
        "    self.log_ent_coe = torch.tensor([1.0], requires_grad=True, device=device)\n",
        "\n",
        "    self.actor_optim = Adam(self.actor.parameters(), lr)\n",
        "    self.Q1_optim = Adam(self.Q1.parameters(), lr)\n",
        "    self.Q2_optim = Adam(self.Q2.parameters(), lr)\n",
        "    self.Ent_optim = Adam([self.log_ent_coe], lr)\n",
        "\n",
        "    self.gamma = gamma\n",
        "    self.max_grad = 1\n",
        "    self.tau = tau\n",
        "    self.target_ent = -np.log(act_size)\n",
        "    self.device = device\n",
        "\n",
        "    self.dict_to_vec = lambda state : torch.from_numpy(\n",
        "        np.concat([state['achieved_goal'], state['desired_goal'], state['observation']], axis = -1)\n",
        "        )\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tensor:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def rollout(self, env, max_step: int, buffer: ReplayBuffer) -> None:\n",
        "    state = env.reset()\n",
        "    state = self.dict_to_vec(state)\n",
        "    scores = None\n",
        "    success = 0\n",
        "    for t in range(max_step):\n",
        "      action, log_prob = self.actor.eval_state(state)\n",
        "      next_state, reward, terminated, info = env.step(action.detach().numpy())\n",
        "      next_state = self.dict_to_vec(next_state)\n",
        "      termination = np.array([info_n['is_success'] for info_n in info])\n",
        "      if any(terminated):\n",
        "        success += np.sum(termination)\n",
        "        state = self.dict_to_vec(env.reset())\n",
        "      termination_mask = torch.from_numpy(1 - termination)\n",
        "      buffer.add_frame(state, next_state, action.detach(), torch.from_numpy(reward), termination_mask)\n",
        "      state = next_state\n",
        "\n",
        "      if scores is None:\n",
        "        scores = reward\n",
        "      else:\n",
        "        scores += reward\n",
        "    return scores.mean(), success\n",
        "\n",
        "  def get_q(self, state: Tensor, action: Tensor) -> Tensor:\n",
        "    q1 = self.Q1(state, action)\n",
        "    q2 = self.Q2(state, action)\n",
        "    return torch.min(q1, q2)\n",
        "\n",
        "  def step_optim(self, loss, model_name: str, logger: Dict | None) -> None:\n",
        "    optimizer = getattr(self, model_name + \"_optim\")\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # model = getattr(self, model_name)\n",
        "    # nn.utils.clip_grad_norm_(model.parameters(), self.max_grad)\n",
        "    optimizer.step()\n",
        "    if logger is not None:\n",
        "      logger[model_name + \"_loss\"] = loss.item()\n",
        "\n",
        "  def polyak_average(self, model, target_model) -> None:\n",
        "    for p, target_p in zip(model.parameters(), target_model.parameters()):\n",
        "      target_p.data.copy_((1 - self.tau) * target_p + self.tau * p)\n",
        "\n",
        "  def update(self, sample: Tuple) -> None:\n",
        "    log_info = {}\n",
        "\n",
        "    state, next_state, action, reward, mask = sample\n",
        "    new_action, log_prob = self.actor.eval_state(state)\n",
        "\n",
        "    ent_loss = -self.log_ent_coe * (log_prob + self.target_ent).detach()\n",
        "    ent_loss = ent_loss.mean()\n",
        "    self.step_optim(ent_loss, \"Ent\", log_info)\n",
        "\n",
        "    ent_coe = torch.exp(self.log_ent_coe.detach())\n",
        "    with torch.no_grad():\n",
        "      next_action, next_log_prob = self.actor.eval_state(next_state)\n",
        "      next_q1 = self.critic1(next_state, next_action)\n",
        "      next_q2 = self.critic2(next_state, next_action)\n",
        "      next_q = torch.min(next_q1, next_q2) - ent_coe * next_log_prob.unsqueeze(1)\n",
        "      target_q = reward + self.gamma * mask * next_q\n",
        "\n",
        "    Q1_value = self.Q1(state, action)\n",
        "    Q2_value = self.Q2(state, action)\n",
        "    Q1_loss = (Q1_value - target_q.detach()).pow(2).mean()\n",
        "    Q2_loss = (Q2_value - target_q.detach()).pow(2).mean()\n",
        "    self.step_optim(Q1_loss, \"Q1\", log_info)\n",
        "    self.step_optim(Q2_loss, \"Q2\", log_info)\n",
        "\n",
        "    new_q = self.get_q(state, new_action)\n",
        "    actor_loss = (ent_coe * log_prob.unsqueeze(1) + new_q).mean()\n",
        "    self.step_optim(actor_loss, \"actor\", log_info)\n",
        "\n",
        "    self.polyak_average(self.Q1, self.critic1)\n",
        "    self.polyak_average(self.Q2, self.critic2)\n",
        "\n",
        "    return log_info"
      ],
      "metadata": {
        "id": "Lgjx61Uj_pFg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "\n",
        "def train(model, env, buffer, episodes: int, max_steps: int,\n",
        "          batch_size: int, update_steps: int, gamma: float, print_per_epi: int, device: str) -> None:\n",
        "  scores = []\n",
        "  losses = []\n",
        "  success_rate = 0\n",
        "  for epi in tqdm(range(episodes)):\n",
        "    score, success = model.rollout(env, max_steps, buffer)\n",
        "    scores.append(score)\n",
        "    success_rate += success\n",
        "\n",
        "    Q1_losses = []\n",
        "    Q2_losses = []\n",
        "    actor_losses = []\n",
        "    for _ in range(update_steps):\n",
        "      log_info = model.update(buffer.random_sample(batch_size))\n",
        "      Q1_losses.append(log_info['Q1_loss'])\n",
        "      Q2_losses.append(log_info['Q2_loss'])\n",
        "      actor_losses.append(log_info['actor_loss'])\n",
        "    losses.append({\n",
        "        \"Q1_loss\": np.mean(Q1_losses),\n",
        "        \"Q2_loss\": np.mean(Q2_losses),\n",
        "        \"actor_loss\": np.mean(actor_losses)\n",
        "        })\n",
        "\n",
        "    if epi % print_per_epi == 0:\n",
        "      L_q1 = 0\n",
        "      L_q2 = 0\n",
        "      L_actor = 0\n",
        "      n = len(losses)\n",
        "      for i in losses:\n",
        "        L_q1 += i[\"Q1_loss\"]\n",
        "        L_q2 += i[\"Q2_loss\"]\n",
        "        L_actor += i[\"actor_loss\"]\n",
        "      print(f\"mean score is {np.mean(scores)}, success_rate is {success_rate / (max_steps * print_per_epi)}\")\n",
        "      print(f\"Q1_loss is {L_q1 / n:.5f}, Q2_loss is {L_q2 / n:.5f}, actor_loss is {L_actor / n:.5f}\")\n",
        "      scores = []\n",
        "      losses = []\n"
      ],
      "metadata": {
        "id": "VDqHyIYYByEq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_envs = 4\n",
        "env_name = \"FetchReach-v4\"\n",
        "eval_env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "print(eval_env.observation_space.sample())\n",
        "print(eval_env.action_space.sample())\n",
        "print(\"--------------------------\")\n",
        "obs_size = 16\n",
        "act_size = 4\n",
        "\n",
        "seed = 0\n",
        "env = VecNormalize(make_vec_env(env_name, n_envs, seed = seed))\n",
        "state = env.reset()\n",
        "print(state)\n",
        "def dict_to_vec(state):\n",
        "  return torch.from_numpy(np.concat([state['achieved_goal'], state['desired_goal'], state['observation']], axis = -1))\n",
        "print(dict_to_vec(state))"
      ],
      "metadata": {
        "id": "kHhliOLkLJHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f35e714b-af34-40df-c4fe-dd949aae5f80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'achieved_goal': array([ 3.61161903,  0.45822068, -0.54496972]), 'desired_goal': array([-0.56726475, -0.46459048, -1.09511917]), 'observation': array([ 0.68497806, -1.05098556, -1.88148002, -1.61562953, -1.3532234 ,\n",
            "        1.33078812,  1.25619465, -1.42892526, -0.38106066, -1.19690965])}\n",
            "[-0.39724004 -0.31798786 -0.54086494  0.19464599]\n",
            "--------------------------\n",
            "OrderedDict({'achieved_goal': array([[0.00400882, 0.00299729, 0.00235733],\n",
            "       [0.00400882, 0.00299729, 0.00235733],\n",
            "       [0.00400882, 0.00299729, 0.00235733],\n",
            "       [0.00400882, 0.00299729, 0.00235733]], dtype=float32), 'desired_goal': array([[ 1.2169112 , -0.5693924 , -1.1366205 ],\n",
            "       [ 0.6380136 ,  1.7233865 , -0.8499632 ],\n",
            "       [-0.5194549 , -0.47270492,  1.0115223 ],\n",
            "       [-1.3334591 , -0.68046874,  0.97554284]], dtype=float32), 'observation': array([[ 4.00882121e-03,  2.99728918e-03,  2.35732808e-03,\n",
            "         1.94986319e-06,  5.85004898e-08, -2.63015956e-08,\n",
            "        -4.23140356e-10,  1.23087375e-07,  3.32709185e-08,\n",
            "        -1.47060275e-08],\n",
            "       [ 4.00882121e-03,  2.99728918e-03,  2.35732808e-03,\n",
            "         1.94986319e-06,  5.85004898e-08, -2.63015956e-08,\n",
            "        -4.23140356e-10,  1.23087375e-07,  3.32709185e-08,\n",
            "        -1.47060275e-08],\n",
            "       [ 4.00882121e-03,  2.99728918e-03,  2.35732808e-03,\n",
            "         1.94986319e-06,  5.85004898e-08, -2.63015956e-08,\n",
            "        -4.23140356e-10,  1.23087375e-07,  3.32709185e-08,\n",
            "        -1.47060275e-08],\n",
            "       [ 4.00882121e-03,  2.99728918e-03,  2.35732808e-03,\n",
            "         1.94986319e-06,  5.85004898e-08, -2.63015956e-08,\n",
            "        -4.23140356e-10,  1.23087375e-07,  3.32709185e-08,\n",
            "        -1.47060275e-08]], dtype=float32)})\n",
            "tensor([[ 4.0088e-03,  2.9973e-03,  2.3573e-03,  1.2169e+00, -5.6939e-01,\n",
            "         -1.1366e+00,  4.0088e-03,  2.9973e-03,  2.3573e-03,  1.9499e-06,\n",
            "          5.8500e-08, -2.6302e-08, -4.2314e-10,  1.2309e-07,  3.3271e-08,\n",
            "         -1.4706e-08],\n",
            "        [ 4.0088e-03,  2.9973e-03,  2.3573e-03,  6.3801e-01,  1.7234e+00,\n",
            "         -8.4996e-01,  4.0088e-03,  2.9973e-03,  2.3573e-03,  1.9499e-06,\n",
            "          5.8500e-08, -2.6302e-08, -4.2314e-10,  1.2309e-07,  3.3271e-08,\n",
            "         -1.4706e-08],\n",
            "        [ 4.0088e-03,  2.9973e-03,  2.3573e-03, -5.1945e-01, -4.7270e-01,\n",
            "          1.0115e+00,  4.0088e-03,  2.9973e-03,  2.3573e-03,  1.9499e-06,\n",
            "          5.8500e-08, -2.6302e-08, -4.2314e-10,  1.2309e-07,  3.3271e-08,\n",
            "         -1.4706e-08],\n",
            "        [ 4.0088e-03,  2.9973e-03,  2.3573e-03, -1.3335e+00, -6.8047e-01,\n",
            "          9.7554e-01,  4.0088e-03,  2.9973e-03,  2.3573e-03,  1.9499e-06,\n",
            "          5.8500e-08, -2.6302e-08, -4.2314e-10,  1.2309e-07,  3.3271e-08,\n",
            "         -1.4706e-08]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 5e-4\n",
        "gamma = 0.99\n",
        "tau = 0.1\n",
        "n_episodes = 1000\n",
        "max_steps = 100\n",
        "update_steps = 50\n",
        "batch_size = 4\n",
        "\n",
        "print_per_epi = 10\n",
        "\n",
        "if seed:\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "model = SAC(obs_size, act_size, lr, gamma, tau, device)\n",
        "buffer = ReplayBuffer(max_steps, n_envs, obs_size, act_size, device)\n",
        "train(model, env, buffer, n_episodes, max_steps, batch_size, update_steps, gamma, print_per_epi, device)"
      ],
      "metadata": {
        "id": "XWZo0r2q_tKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bb31fe5865c74bffa1d1998b02ab3bd0",
            "4d9084cd415a4fe3813adc1a1e0a1cf8",
            "0a99f9d606684d44a04e27067a64c856",
            "387e2e74f7464d72a1786a0ac0c15860",
            "4f1158a641064b9a9ba7590a2a18db62",
            "21eb4962cf734e989c869c4a4ae50522",
            "387be76ad2574881a772b8912ab670f3",
            "efee8ff236eb48e1b1a41711b2fbd46f",
            "efef01e7d37d4702acc82fc6e11a6519",
            "5cee2fa67082490bbc548156b8662c18",
            "41698135b00b43cdb653378a665c49d2"
          ]
        },
        "outputId": "5d7a0251-11df-4552-aeea-2a22c1be42ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb31fe5865c74bffa1d1998b02ab3bd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean score is -27.88772964477539, success_rate is 0.0\n",
            "Q1_loss is 4.28689, Q2_loss is 4.30449, actor_loss is -7.45056\n",
            "mean score is -8.746698379516602, success_rate is 0.0010000000474974513\n",
            "Q1_loss is 2.55527, Q2_loss is 2.55724, actor_loss is -6.54660\n",
            "mean score is -8.825740814208984, success_rate is 0.0020000000949949026\n",
            "Q1_loss is 2.23792, Q2_loss is 2.23857, actor_loss is -5.09553\n",
            "mean score is -8.793031692504883, success_rate is 0.0020000000949949026\n",
            "Q1_loss is 1.45892, Q2_loss is 1.45990, actor_loss is -4.05008\n",
            "mean score is -8.745903015136719, success_rate is 0.003000000026077032\n",
            "Q1_loss is 0.91136, Q2_loss is 0.91143, actor_loss is -3.18464\n",
            "mean score is -8.744513511657715, success_rate is 0.003000000026077032\n",
            "Q1_loss is 0.94709, Q2_loss is 0.94761, actor_loss is -2.51247\n",
            "mean score is -8.778531074523926, success_rate is 0.004999999888241291\n",
            "Q1_loss is 0.99066, Q2_loss is 0.99125, actor_loss is -2.00470\n",
            "mean score is -8.782065391540527, success_rate is 0.004999999888241291\n",
            "Q1_loss is 0.79570, Q2_loss is 0.79698, actor_loss is -1.55347\n",
            "mean score is -8.854289054870605, success_rate is 0.004999999888241291\n",
            "Q1_loss is 1.10551, Q2_loss is 1.10589, actor_loss is -1.27372\n",
            "mean score is -8.830328941345215, success_rate is 0.006000000052154064\n",
            "Q1_loss is 1.06480, Q2_loss is 1.06613, actor_loss is -1.04410\n",
            "mean score is -8.799546241760254, success_rate is 0.007000000216066837\n",
            "Q1_loss is 1.41732, Q2_loss is 1.41932, actor_loss is -0.89687\n",
            "mean score is -8.775771141052246, success_rate is 0.008999999612569809\n",
            "Q1_loss is 1.45525, Q2_loss is 1.45778, actor_loss is -0.74912\n",
            "mean score is -8.77978229522705, success_rate is 0.009999999776482582\n",
            "Q1_loss is 0.73058, Q2_loss is 0.73078, actor_loss is -0.59179\n",
            "mean score is -8.863165855407715, success_rate is 0.009999999776482582\n",
            "Q1_loss is 0.51905, Q2_loss is 0.51943, actor_loss is -0.47170\n",
            "mean score is -8.776859283447266, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.82418, Q2_loss is 0.82443, actor_loss is -0.42870\n",
            "mean score is -8.838647842407227, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.56778, Q2_loss is 0.56809, actor_loss is -0.36225\n",
            "mean score is -8.752398490905762, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.82193, Q2_loss is 0.82206, actor_loss is -0.33621\n",
            "mean score is -8.734747886657715, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.73593, Q2_loss is 0.73725, actor_loss is -0.29898\n",
            "mean score is -8.725348472595215, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.67379, Q2_loss is 0.67457, actor_loss is -0.26331\n",
            "mean score is -8.767053604125977, success_rate is 0.010999999940395355\n",
            "Q1_loss is 0.74715, Q2_loss is 0.74826, actor_loss is -0.25575\n",
            "mean score is -8.790456771850586, success_rate is 0.012000000104308128\n",
            "Q1_loss is 0.48215, Q2_loss is 0.48243, actor_loss is -0.21078\n",
            "mean score is -8.780261039733887, success_rate is 0.012000000104308128\n",
            "Q1_loss is 0.60157, Q2_loss is 0.60227, actor_loss is -0.19489\n",
            "mean score is -8.772491455078125, success_rate is 0.012000000104308128\n",
            "Q1_loss is 0.52063, Q2_loss is 0.52080, actor_loss is -0.18407\n",
            "mean score is -8.723135948181152, success_rate is 0.013000000268220901\n",
            "Q1_loss is 0.70916, Q2_loss is 0.70912, actor_loss is -0.19996\n",
            "mean score is -8.811430931091309, success_rate is 0.014000000432133675\n",
            "Q1_loss is 0.62788, Q2_loss is 0.62829, actor_loss is -0.19534\n",
            "mean score is -8.794270515441895, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.52364, Q2_loss is 0.52378, actor_loss is -0.16617\n",
            "mean score is -8.824224472045898, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.69742, Q2_loss is 0.69810, actor_loss is -0.19224\n",
            "mean score is -8.861799240112305, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.55694, Q2_loss is 0.55730, actor_loss is -0.17740\n",
            "mean score is -8.8560791015625, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.92079, Q2_loss is 0.92111, actor_loss is -0.20935\n",
            "mean score is -8.853598594665527, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.55852, Q2_loss is 0.55980, actor_loss is -0.18678\n",
            "mean score is -8.855484008789062, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.87751, Q2_loss is 0.87830, actor_loss is -0.20276\n",
            "mean score is -8.829498291015625, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.59683, Q2_loss is 0.59701, actor_loss is -0.18099\n",
            "mean score is -8.863408088684082, success_rate is 0.014999999664723873\n",
            "Q1_loss is 1.09482, Q2_loss is 1.09480, actor_loss is -0.19977\n",
            "mean score is -8.861587524414062, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.82304, Q2_loss is 0.82312, actor_loss is -0.20754\n",
            "mean score is -8.848917007446289, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.52282, Q2_loss is 0.52314, actor_loss is -0.18590\n",
            "mean score is -8.84542465209961, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.74637, Q2_loss is 0.74649, actor_loss is -0.18295\n",
            "mean score is -8.852923393249512, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.88263, Q2_loss is 0.88254, actor_loss is -0.24098\n",
            "mean score is -8.844636917114258, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.85195, Q2_loss is 0.85277, actor_loss is -0.22309\n",
            "mean score is -8.852258682250977, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.70150, Q2_loss is 0.70229, actor_loss is -0.19043\n",
            "mean score is -8.811263084411621, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.62860, Q2_loss is 0.62867, actor_loss is -0.19053\n",
            "mean score is -8.858640670776367, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.95900, Q2_loss is 0.95927, actor_loss is -0.23915\n",
            "mean score is -8.868460655212402, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.67064, Q2_loss is 0.67078, actor_loss is -0.19117\n",
            "mean score is -8.862760543823242, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.82059, Q2_loss is 0.82133, actor_loss is -0.22591\n",
            "mean score is -8.766107559204102, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.70630, Q2_loss is 0.70691, actor_loss is -0.19072\n",
            "mean score is -8.86091423034668, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.89096, Q2_loss is 0.88970, actor_loss is -0.22060\n",
            "mean score is -8.85099983215332, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.88872, Q2_loss is 0.88836, actor_loss is -0.23006\n",
            "mean score is -8.825634956359863, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.74739, Q2_loss is 0.74830, actor_loss is -0.19749\n",
            "mean score is -8.844797134399414, success_rate is 0.014999999664723873\n",
            "Q1_loss is 0.48170, Q2_loss is 0.48247, actor_loss is -0.18622\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2871709513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_envs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_per_epi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2690353554.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, env, buffer, episodes, max_steps, batch_size, update_steps, gamma, print_per_epi, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0msuccess_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msuccess_rate\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2092946569.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, env, max_step, buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3601139064.py\u001b[0m in \u001b[0;36meval_state\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbounded_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shift the result to valid region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtanh_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mlog_prob\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtanh_fix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbounded_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "\n",
        "\n",
        "images = []\n",
        "\n",
        "state, _ = eval_env.reset()\n",
        "state = dict_to_vec(state).to(torch.float)\n",
        "images.append(eval_env.render())\n",
        "\n",
        "for i in range(50):\n",
        "  action = model.actor.get_action(state)\n",
        "  state, reward, terminated, truncated, _ = eval_env.step(action.detach().numpy())\n",
        "  state = dict_to_vec(state).to(torch.float)\n",
        "  # images.append(eval_env.render())\n",
        "\n",
        "imageio.mimsave(\"./result.gif\", images)"
      ],
      "metadata": {
        "id": "0Lm6J4DidWLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stable_baselines3 as sb\n",
        "from stable_baselines3.sac.policies import MultiInputPolicy\n",
        "\n",
        "env_name = \"FetchReach-v4\"\n",
        "model = sb.SAC(MultiInputPolicy, env_name, verbose=1)\n",
        "model.learn(total_timesteps=50000, log_interval=10)"
      ],
      "metadata": {
        "id": "vyK_8PT5-lri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06b3fabe-c123-4dd7-b55f-1f2a9c67e4b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'FetchReach-v4'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.2    |\n",
            "|    success_rate    | 0.1      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 500      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.24    |\n",
            "|    critic_loss     | 0.0853   |\n",
            "|    ent_coef        | 0.887    |\n",
            "|    ent_coef_loss   | -0.804   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 399      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.4    |\n",
            "|    success_rate    | 0.05     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 30       |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 1000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.23    |\n",
            "|    critic_loss     | 0.0262   |\n",
            "|    ent_coef        | 0.764    |\n",
            "|    ent_coef_loss   | -1.81    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 899      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.0333   |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 29       |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 1500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.79    |\n",
            "|    critic_loss     | 0.0457   |\n",
            "|    ent_coef        | 0.657    |\n",
            "|    ent_coef_loss   | -2.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.025    |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 70       |\n",
            "|    total_timesteps | 2000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.6    |\n",
            "|    critic_loss     | 0.0627   |\n",
            "|    ent_coef        | 0.566    |\n",
            "|    ent_coef_loss   | -3.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49      |\n",
            "|    success_rate    | 0.04     |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 28       |\n",
            "|    time_elapsed    | 88       |\n",
            "|    total_timesteps | 2500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.1    |\n",
            "|    critic_loss     | 0.0302   |\n",
            "|    ent_coef        | 0.487    |\n",
            "|    ent_coef_loss   | -4.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49      |\n",
            "|    success_rate    | 0.0333   |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 107      |\n",
            "|    total_timesteps | 3000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -11.1    |\n",
            "|    critic_loss     | 0.0198   |\n",
            "|    ent_coef        | 0.419    |\n",
            "|    ent_coef_loss   | -5.82    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.0286   |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 3500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.7    |\n",
            "|    critic_loss     | 0.0168   |\n",
            "|    ent_coef        | 0.361    |\n",
            "|    ent_coef_loss   | -6.86    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.025    |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 143      |\n",
            "|    total_timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10      |\n",
            "|    critic_loss     | 0.0285   |\n",
            "|    ent_coef        | 0.311    |\n",
            "|    ent_coef_loss   | -7.88    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.0222   |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 161      |\n",
            "|    total_timesteps | 4500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.12    |\n",
            "|    critic_loss     | 0.0393   |\n",
            "|    ent_coef        | 0.267    |\n",
            "|    ent_coef_loss   | -8.83    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.8    |\n",
            "|    success_rate    | 0.02     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 180      |\n",
            "|    total_timesteps | 5000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.91    |\n",
            "|    critic_loss     | 0.0259   |\n",
            "|    ent_coef        | 0.23     |\n",
            "|    ent_coef_loss   | -9.84    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.9    |\n",
            "|    success_rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 198      |\n",
            "|    total_timesteps | 5500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.5     |\n",
            "|    critic_loss     | 0.0235   |\n",
            "|    ent_coef        | 0.198    |\n",
            "|    ent_coef_loss   | -10.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -48.9    |\n",
            "|    success_rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 217      |\n",
            "|    total_timesteps | 6000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5       |\n",
            "|    critic_loss     | 0.0347   |\n",
            "|    ent_coef        | 0.171    |\n",
            "|    ent_coef_loss   | -11.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.1    |\n",
            "|    success_rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 234      |\n",
            "|    total_timesteps | 6500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.33    |\n",
            "|    critic_loss     | 0.0111   |\n",
            "|    ent_coef        | 0.147    |\n",
            "|    ent_coef_loss   | -12.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.3    |\n",
            "|    success_rate    | 0.01     |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 252      |\n",
            "|    total_timesteps | 7000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.59    |\n",
            "|    critic_loss     | 0.0104   |\n",
            "|    ent_coef        | 0.126    |\n",
            "|    ent_coef_loss   | -14      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 272      |\n",
            "|    total_timesteps | 7500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 0.191    |\n",
            "|    critic_loss     | 0.016    |\n",
            "|    ent_coef        | 0.109    |\n",
            "|    ent_coef_loss   | -15      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.2    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 290      |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 1.95     |\n",
            "|    critic_loss     | 0.0298   |\n",
            "|    ent_coef        | 0.0936   |\n",
            "|    ent_coef_loss   | -15.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.4    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 170      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 308      |\n",
            "|    total_timesteps | 8500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.77     |\n",
            "|    critic_loss     | 0.025    |\n",
            "|    ent_coef        | 0.0805   |\n",
            "|    ent_coef_loss   | -16.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 326      |\n",
            "|    total_timesteps | 9000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.58     |\n",
            "|    critic_loss     | 0.0166   |\n",
            "|    ent_coef        | 0.0694   |\n",
            "|    ent_coef_loss   | -17.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.3    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 190      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 347      |\n",
            "|    total_timesteps | 9500     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 7.4      |\n",
            "|    critic_loss     | 0.0142   |\n",
            "|    ent_coef        | 0.0598   |\n",
            "|    ent_coef_loss   | -18.8    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9399     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.2    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 365      |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 9.26     |\n",
            "|    critic_loss     | 0.0144   |\n",
            "|    ent_coef        | 0.0515   |\n",
            "|    ent_coef_loss   | -19.4    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.2    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 210      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 384      |\n",
            "|    total_timesteps | 10500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 11.1     |\n",
            "|    critic_loss     | 0.0202   |\n",
            "|    ent_coef        | 0.0445   |\n",
            "|    ent_coef_loss   | -20.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10399    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49.1    |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 402      |\n",
            "|    total_timesteps | 11000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 13       |\n",
            "|    critic_loss     | 0.0234   |\n",
            "|    ent_coef        | 0.0384   |\n",
            "|    ent_coef_loss   | -20.7    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 10899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 50       |\n",
            "|    ep_rew_mean     | -49      |\n",
            "|    success_rate    | 0        |\n",
            "| time/              |          |\n",
            "|    episodes        | 230      |\n",
            "|    fps             | 27       |\n",
            "|    time_elapsed    | 421      |\n",
            "|    total_timesteps | 11500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 14.8     |\n",
            "|    critic_loss     | 0.0196   |\n",
            "|    ent_coef        | 0.0332   |\n",
            "|    ent_coef_loss   | -20.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11399    |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3027624255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"FetchReach-v4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiInputPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     ) -> SelfSAC:\n\u001b[0;32m--> 313\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;31m# Compute actor loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}